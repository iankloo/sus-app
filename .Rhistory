facts_date <- as.Date(colnames(main)[length(colnames(main))], format = '%m/%d/%y')
#---improved munge script for covid data
suppressWarnings({
suppressMessages({
library(data.table)
library(RSQLite)
library(DBI)
library(dplyr)
library(dbplyr)
library(mixdist)
library(extraDistr)
library(jsonlite)
library(geojsonio)
library(sp)
})
})
setwd('~/working/cov_api')
#functions used
rt.func.v2<-function(dat,mean.Weibull=4.8,sd.Weibull=2.3){
r.vals<-numeric(length = (length(dat) - 2))
#get the Weibull parameters from mixdist's weibullpar function
mGT.params<-weibullpar(mean.Weibull, sd.Weibull, loc = 0)
alpha<-mGT.params[2] # called shape in weibullpar, alpha in a discrete Weilbull
beta<-mGT.params[1] # called scale in weibullpar, beta in a discrete Weibull
#the extraDistr package uses an altrnative parameterization of the Weibull (q, beta) from
#Nakagawa and Osaki (1975) where q = exp(-alpha^-beta), so...
q<-exp(-as.numeric(alpha)^(-as.numeric(beta)))
#Discretize Weibull via the extraDistr package's ddweibull function
w<- ddweibull(0:1000, as.numeric(q), as.numeric(beta), log = FALSE)
growth<-diff(dat)
growth<-pmax(growth, 0) # eliminate any erroneous downward shifts in the cumulative counts
#Estimate R(t) from equation (33) of Nishiura and Chowell (2009)
for(k in 2:length(growth)){
r.vals[k-1]<-growth[k]/(sum(growth[1:k]*rev(w[1:k])))
}
#Output the results
return(c(NA, NA, r.vals))
}
covid_db <- dbConnect(RSQLite::SQLite(), 'data/covid_db.sqlite')
#---check if need to update
suppressWarnings({
suppressMessages({
x <- tbl(covid_db, 'counties') %>%
filter(date == max(date, na.rm = TRUE)) %>%
select(date) %>%
collect()
})
})
db_date <- as.Date(x[1][[1]][1])
main <- fread('https://usafactsstatic.blob.core.windows.net/public/data/covid-19/covid_confirmed_usafacts.csv', colClasses = 'character', showProgress = FALSE)
main <- main[countyFIPS != '0']
keep_cols <- grep('V',colnames(main), invert = TRUE)
main <- main[, keep_cols, with=FALSE]
facts_date <- as.Date(colnames(main)[length(colnames(main))], format = '%m/%d/%y')
#---improved munge script for covid data
suppressWarnings({
suppressMessages({
library(data.table)
library(RSQLite)
library(DBI)
library(dplyr)
library(dbplyr)
library(mixdist)
library(extraDistr)
library(jsonlite)
library(geojsonio)
library(sp)
})
})
setwd('~/working/cov_api')
#functions used
rt.func.v2<-function(dat,mean.Weibull=4.8,sd.Weibull=2.3){
r.vals<-numeric(length = (length(dat) - 2))
#get the Weibull parameters from mixdist's weibullpar function
mGT.params<-weibullpar(mean.Weibull, sd.Weibull, loc = 0)
alpha<-mGT.params[2] # called shape in weibullpar, alpha in a discrete Weilbull
beta<-mGT.params[1] # called scale in weibullpar, beta in a discrete Weibull
#the extraDistr package uses an altrnative parameterization of the Weibull (q, beta) from
#Nakagawa and Osaki (1975) where q = exp(-alpha^-beta), so...
q<-exp(-as.numeric(alpha)^(-as.numeric(beta)))
#Discretize Weibull via the extraDistr package's ddweibull function
w<- ddweibull(0:1000, as.numeric(q), as.numeric(beta), log = FALSE)
growth<-diff(dat)
growth<-pmax(growth, 0) # eliminate any erroneous downward shifts in the cumulative counts
#Estimate R(t) from equation (33) of Nishiura and Chowell (2009)
for(k in 2:length(growth)){
r.vals[k-1]<-growth[k]/(sum(growth[1:k]*rev(w[1:k])))
}
#Output the results
return(c(NA, NA, r.vals))
}
covid_db <- dbConnect(RSQLite::SQLite(), 'data/covid_db.sqlite')
#---check if need to update
suppressWarnings({
suppressMessages({
x <- tbl(covid_db, 'counties') %>%
filter(date == max(date, na.rm = TRUE)) %>%
select(date) %>%
collect()
})
})
db_date <- as.Date(x[1][[1]][1])
main <- fread('https://usafactsstatic.blob.core.windows.net/public/data/covid-19/covid_confirmed_usafacts.csv', colClasses = 'character', showProgress = FALSE)
main <- main[countyFIPS != '0']
keep_cols <- grep('V',colnames(main), invert = TRUE)
main <- main[, keep_cols, with=FALSE]
facts_date <- as.Date(colnames(main)[length(colnames(main))], format = '%m/%d/%y')
#if newer date in usafacts than db
if(db_date != facts_date){
#---finish cleaning up the usafacts data
main[nchar(countyFIPS) == 4, 'countyFIPS'] <- paste0('0', main[nchar(countyFIPS) == 4, countyFIPS])
df <- melt.data.table(main, id.vars = 1:4, measure.vars = 5:ncol(main), variable.name = 'date', value.name = 'case_count')
df[, date := as.Date(as.character(date), format = '%m/%d/%y')][
, case_count := as.integer(gsub(',', '', case_count))
]
#add daily growth
df[, delta := lapply(.SD, function(d) d - shift(d)), by = countyFIPS, .SDcols = 'case_count']
#add percent increase
df[, per_delta := lapply(.SD, function(d) (d - shift(d))/shift(d)), by = countyFIPS, .SDcols = 'case_count']
df[is.nan(per_delta), 'per_delta'] <- NA
df[is.infinite(per_delta), 'per_delta'] <- NA
#add rt
df[, r_t := rt.func.v2(case_count), by = 'countyFIPS']
#brind in deaths
deaths <- fread('https://usafactsstatic.blob.core.windows.net/public/data/covid-19/covid_deaths_usafacts.csv',
colClasses = 'character', showProgress = FALSE)
#drop bad data
d <- deaths[duplicated(deaths) == FALSE]
d <- d[countyFIPS != '0']
keep_cols <- grep('V',colnames(d), invert = TRUE)
d <- d[, keep_cols, with=FALSE]
#fix fips codes with leading 0
d[nchar(countyFIPS) == 4, 'countyFIPS'] <- paste0('0', d[nchar(countyFIPS) == 4, countyFIPS])
d <- melt.data.table(d, id.vars = 1:4, measure.vars = 5:ncol(d), variable.name = 'date', value.name = 'deaths')
d[, date := as.Date(as.character(date), format = '%m/%d/%y')][
, deaths := as.integer(gsub(',', '', deaths))
]
d <- d[, c('countyFIPS', 'date', 'deaths')]
setkeyv(d, c('countyFIPS', 'date'))
setkeyv(df, c('countyFIPS', 'date'))
#merge deaths
df <- d[df]
#--add pops
pop <- fread('https://www2.census.gov/programs-surveys/popest/datasets/2010-2019/counties/totals/co-est2019-alldata.csv',
colClasses = 'character', showProgress = FALSE)
pop[, countyFIPS := paste0(STATE, COUNTY)]
pop <- pop[, c('countyFIPS', 'POPESTIMATE2019')]
pop[, pop := as.numeric(POPESTIMATE2019)]
pop <- pop[, c('countyFIPS', 'pop')]
setkey(pop, countyFIPS)
setkey(df, countyFIPS)
df <- pop[df]
#---per capita cases and deaths
#df[, cases_per_10k := (case_count / pop) * 10000]
#df[, deaths_per_10k := (deaths / pop) * 10000]
#---moving averages
df <- df[order(countyFIPS, date)]
df <- df[, r_t_three := frollmean(r_t, n = 3), by = countyFIPS]
df <- df[, r_t_seven := frollmean(r_t, n = 7), by = countyFIPS]
final <- list()
u_id <- unique(df$countyFIPS)
pb <- txtProgressBar(max = length(u_id), style = 3)
for(j in 1:length(u_id)){
sub <- df[countyFIPS == u_id[j]]
sub <- sub[order(-date)]
out <- list()
for(i in 1:length(sub$case_count)){
half <- sub$case_count[i]/2
index <- which(sub$case_count < half)[1]
out[[i]] <- as.numeric(sub$date[index] - sub$date[i]) * -1
}
sub[, doubling := unlist(out)]
final[[j]] <- sub
setTxtProgressBar(pb, j)
}
df <- rbindlist(final)
df <- df[order(date)]
#---check if day before agrees with data as a check...
yesterday <- as.character(max(df$date) - 1)
df[, date := as.character(date)]
x <- tbl(covid_db, 'counties') %>%
filter(date == yesterday, countyFIPS == '01001') %>%
select(r_t) %>%
collect()
good <- x$r_t == df[date == yesterday & countyFIPS == '01001', r_t]
if(good){
dbWriteTable(covid_db, 'counties', df, overwrite = TRUE)
covid_db <- dbConnect(RSQLite::SQLite(), 'data/covid_db.sqlite')
dat <- tbl(covid_db, 'counties') %>%
select(countyFIPS, date, case_count, per_delta, r_t, deaths, doubling, r_t_seven, r_t_three) %>%
distinct() %>%
collect()
dat <- data.table(dat)
dat <- dat[as.Date(dat$date) >= '2020-03-01',]
# dat <- jsonlite::fromJSON(paste0('http://160.1.89.242/alldata?min_date=20200301&max_date=', gsub('-', '', Sys.Date() - 1)))
# dat <- data.table(dat)
dat[, r_t := round(r_t, 2)]
dat[, r_t_three := round(r_t_three, 2)]
dat[, r_t_seven := round(r_t_seven, 2)]
dat[, per_delta := round(per_delta* 100, 2) ]
#---make wide timeseries data - every variable/date combo gets a column
u_id <- unique(dat$countyFIPS)
out <- list()
pb <- txtProgressBar(max = length(u_id), style = 3)
for(i in 1:length(u_id)){
sub <- dat[countyFIPS == u_id[i]]
sub <- unique(sub, by=c("countyFIPS", "date"))
out_tmp <- list()
for(j in 1:nrow(sub)){
cols <- paste0(colnames(sub)[3:ncol(sub)],'_', gsub('-', '', sub$date[j]))
tmp <- data.frame(sub[j, 3:ncol(sub)])
colnames(tmp) <- cols
out_tmp[[j]] <- tmp
}
z <- cbind(sub[1, 1], do.call('cbind', out_tmp))
out[[i]] <- z
setTxtProgressBar(pb, i)
}
final <- rbindlist(out)
#merge into county shapes
county_shapes <- readRDS('data/all_counties.RDS')
rn <- row.names(county_shapes@data)
county_shapes$STATE <- as.character(county_shapes$STATE)
county_shapes$COUNTY <- as.character(county_shapes$COUNTY)
county_shapes$FIPS <- paste0(county_shapes$STATE, county_shapes$COUNTY)
county_shapes <- sp::merge(county_shapes, final, by.x = 'FIPS', by.y = 'countyFIPS')
row.names(county_shapes) <- rn
#geojsonio::geojson_write(county_shapes, file = "data/bigmap/ts.geojson")
geojsonio::geojson_write(county_shapes, file = "~/working/bigmap/ts.geojson")
geojsonio::geojson_write(county_shapes, file = "~/working/bigmap_alt/ts.geojson")
setwd('~/working/bigmap')
system('git add --all')
system('git commit -m "update"')
system('git push')
setwd('~/working/bigmap_alt')
system('git add --all')
system('git commit -m "update"')
system('git push')
print(paste0('Successful update at: ', Sys.time()))
update_history <- read.csv('~/working/cov_api/update_history.csv', stringsAsFactors = FALSE)
update_history <- rbind(update_history, data.frame(date = as.character(Sys.time())))
write.csv(update_history, '~/working/cov_api/update_history.csv', row.names = FALSE)
}
} else{
print(paste0('No update at: ', Sys.time()))
}
library(data.table)
df <- fread('~/Downloads/SE370 Feedback.csv')
df
df <- fread('~/Downloads/SE370 Feedback.csv')
View(df)
df <- df[, 10:ncol(df)]
View(df)
is.numeric(df[,1])
df[,1]
df[1,1]
is.numeric(df[1,1])
as.numeric(df[1,1])
as.numeric(df[1,10])
as.numeric(df[1,48])
?apply
apply(df, 2, as.numeric)
num <- apply(df, 2, as.numeric)
num[is.na(num) == FALSE]
num <- num[is.na(num) == FALSE]
num <- apply(df[1,], 2, as.numeric)
num <- num[is.na(num) == FALSE]
survey <- df[, 1:length(num)]
txt <- df[, (length(num) + 1):ncol(df)]
View(survey)
library(htmltools)
colnames(survey)
gsub('.?(Question #[0-9]+: .*)', '\\1', colnames(survey))
gsub('.?(Question #[0-9]+: .*)', '\\1', colnames(survey)[1])
gsub('.?(Question #[0-9]+: )', '\\1', colnames(survey)[1])
gsub('.?( Question : )', '\\1', colnames(survey)[1])
gsub('.?( Question )', '\\1', colnames(survey)[1])
gsub('.?( Question )', '\\1', colnames(survey)[1])
gsub('.?( Question )', '//1', colnames(survey)[1])
gsub('.?( Question )', '\\1', colnames(survey)[1])
gsub('.?( Question #)', '\\1', colnames(survey)[1])
gsub('.?( Question #)', '//1', colnames(survey)[1])
gsub('.?( Question #.*)', '\\1', colnames(survey)[1])
gsub('.?( Question #.*)', '//1', colnames(survey)[1])
gsub('(.? )Question #.*', '', colnames(survey)[1])
colnames(survey)[1]
gsub('(.? )Question \#.*', '', colnames(survey)[1])
gsub('(.? )Question \\#.*', '', colnames(survey)[1])
qs <- gsub('.*(Question .*)', '\\1', colnames(survey))
colnames(survey) <- gsub('.*(Question .*)', '\\1', colnames(survey))
library(ggplot2)
survey[1,]
View(survey)
ggplot(survey[,1], aes())
survey[,1]
sub <- survey[,1]
sub[, .(count = .N)]
colnames(sub) <- 'tmp'
sub[, .(count = .N), by = 'tmp']
sub <- survey[,1]
colnames(sub) <- 'response'
sub[, .(count = .N), by = 'response']
all <- c(1,2,3,4,5)
all <- c(1:5)
1 %in% sub$response
!1 %in% sub$response
sub
sub
sub <- sub[, .(count = .N), by = 'response']
sub
sub
rbind(data.table(response == 1, count = 0))
rbind(data.table(response == 1, count = 0), sub)
rbind(data.table(response = 1, count = 0), sub)
for(j in 1:5){
if(!j %in% sub$response){
sub <- rbind(data.table(response = j, count = 0), sub)
}
}
sub
sub[, response := factor(response, levels = c(1:5))]
View(sub)
sub
ggplot(sub, aes(x = response, y = count))
ggplot(sub, aes(x = response, y = count)) + geom_bar()
ggplot(sub, aes(x = response, y = count)) + geom_bar(stat = 'identity')
ggplot(sub, aes(x = response, y = count)) + geom_bar(stat = 'identity') + theme_bw
ggplot(sub, aes(x = response, y = count)) + geom_bar(stat = 'identity') + theme_bw()
ggplot(sub, aes(x = response, y = count)) + geom_bar(stat = 'identity') + theme_bw()
for(i in 1:length(survey)){
print(h4(colnames(survey)[i]))
sub <- survey[,i]
colnames(sub) <- 'response'
sub <- sub[, .(count = .N), by = 'response']
for(j in 1:5){
if(!j %in% sub$response){
sub <- rbind(data.table(response = j, count = 0), sub)
}
}
sub[, response := factor(response, levels = c(1:5))]
ggplot(sub, aes(x = response, y = count)) + geom_bar(stat = 'identity') + theme_bw()
}
i <- 1
print(h4(colnames(survey)[i]))
sub <- survey[,i]
sub <- survey[,i, with = TRUE]
print(h4(colnames(survey)[i]))
survey[,i]
i
sub <- survey[,i, with = TRUE]
sub <- survey[, ..i, with = TRUE]
sub <- survey[, ..i]
colnames(sub) <- 'response'
sub <- sub[, .(count = .N), by = 'response']
for(j in 1:5){
if(!j %in% sub$response){
sub <- rbind(data.table(response = j, count = 0), sub)
}
}
sub[, response := factor(response, levels = c(1:5))]
ggplot(sub, aes(x = response, y = count)) + geom_bar(stat = 'identity') + theme_bw()
library(plumber)
library(servr)
servr::httd('.', port = '80', host = '0.0.0.0', daemon = TRUE)
servr::daemon_stop(1)
setwd('~/Documents/projects/nag/d3_dev/')
servr::httd('.', port = '80', host = '0.0.0.0', daemon = TRUE)
api_obj <- plumber::plumb('plumber.R')
api_obj$run(port = 8080, host = '0.0.0.0')
api_obj <- plumber::plumb('plumber.R')
api_obj$run(port = 8080, host = '0.0.0.0')
api_obj <- plumber::plumb('plumber.R')
api_obj$run(port = 8080, host = '0.0.0.0')
N.bootstrap <- 1000
ci.hw.increase <- 0
b <- bootstrap(y, mean(y), R = N.bootstrap)
b <- bootstrap(sus_scores, mean(sus_scores), R = N.bootstrap)
??bootstrap
library(e1071)
?bootstrap
??sn
library(resample)
api_obj <- plumber::plumb('plumber.R')
api_obj$run(port = 8080, host = '0.0.0.0')
api_obj <- plumber::plumb('plumber.R')
api_obj$run(port = 8080, host = '0.0.0.0')
servr::httd('.', port = '80', host = '0.0.0.0', daemon = TRUE)
servr::daemon_stop(1)
servr::httd('.', port = '80', host = '0.0.0.0', daemon = TRUE)
api_obj <- plumber::plumb('plumber.R')
api_obj$run(port = 8080, host = '0.0.0.0')
api_obj <- plumber::plumb('plumber.R')
api_obj$run(port = 8080, host = '0.0.0.0')
plumb(file='plumber.R')$run()
api_obj <- plumber::plumb('plumber.R')
api_obj$run(port = 8080, host = '0.0.0.0')
api_obj <- plumber::plumb('plumber.R')
api_obj$run(port = 8080, host = '0.0.0.0')
api_obj <- plumber::plumb('plumber.R')
api_obj$run(port = 8080, host = '0.0.0.0')
api_obj <- plumber::plumb('plumber.R')
api_obj$run(port = 8080, host = '0.0.0.0')
api_obj <- plumber::plumb('plumber.R')
api_obj$run(port = 8080, host = '0.0.0.0')
api_obj <- plumber::plumb('plumber.R')
api_obj$run(port = 8080, host = '0.0.0.0')
#---improved munge script for covid data
suppressWarnings({
suppressMessages({
library(data.table)
library(RSQLite)
library(DBI)
library(dplyr)
library(dbplyr)
library(mixdist)
library(extraDistr)
library(jsonlite)
library(geojsonio)
library(sp)
})
})
setwd('~/working/cov_api')
#functions used
rt.func.v2<-function(dat,mean.Weibull=4.8,sd.Weibull=2.3){
r.vals<-numeric(length = (length(dat) - 2))
#get the Weibull parameters from mixdist's weibullpar function
mGT.params<-weibullpar(mean.Weibull, sd.Weibull, loc = 0)
alpha<-mGT.params[2] # called shape in weibullpar, alpha in a discrete Weilbull
beta<-mGT.params[1] # called scale in weibullpar, beta in a discrete Weibull
#the extraDistr package uses an altrnative parameterization of the Weibull (q, beta) from
#Nakagawa and Osaki (1975) where q = exp(-alpha^-beta), so...
q<-exp(-as.numeric(alpha)^(-as.numeric(beta)))
#Discretize Weibull via the extraDistr package's ddweibull function
w<- ddweibull(0:1000, as.numeric(q), as.numeric(beta), log = FALSE)
growth<-diff(dat)
growth<-pmax(growth, 0) # eliminate any erroneous downward shifts in the cumulative counts
#Estimate R(t) from equation (33) of Nishiura and Chowell (2009)
for(k in 2:length(growth)){
r.vals[k-1]<-growth[k]/(sum(growth[1:k]*rev(w[1:k])))
}
#Output the results
return(c(NA, NA, r.vals))
}
covid_db <- dbConnect(RSQLite::SQLite(), 'data/covid_db.sqlite')
#---check if need to update
suppressWarnings({
suppressMessages({
x <- tbl(covid_db, 'counties') %>%
filter(date == max(date, na.rm = TRUE)) %>%
select(date) %>%
collect()
})
})
db_date <- as.Date(x[1][[1]][1])
main <- fread('https://usafactsstatic.blob.core.windows.net/public/data/covid-19/covid_confirmed_usafacts.csv', colClasses = 'character', showProgress = FALSE)
main <- main[countyFIPS != '0']
keep_cols <- grep('V',colnames(main), invert = TRUE)
main <- main[, keep_cols, with=FALSE]
facts_date <- as.Date(colnames(main)[length(colnames(main))], format = '%m/%d/%y')
?ggpairs
api_obj <- plumber::plumb('plumber.R')
api_obj$run(port = 8080, host = '0.0.0.0')
api_obj <- plumber::plumb('plumber.R')
api_obj$run(port = 8080, host = '0.0.0.0')
servr::daemon_stop(1)
servr::httd('.', port = '80', host = '0.0.0.0', daemon = TRUE)
api_obj <- plumber::plumb('plumber.R')
api_obj$run(port = 8080, host = '0.0.0.0')
api_obj <- plumber::plumb('plumber.R')
api_obj$run(port = 8080, host = '0.0.0.0')
api_obj <- plumber::plumb('plumber.R')
api_obj$run(port = 8080, host = '0.0.0.0')
getwd()
setwd("~/Documents/projects/nag/d3_dev")
api_obj <- plumber::plumb('plumber.R')
api_obj$run(port = 8080, host = '0.0.0.0')
setwd("~/Documents/projects/nag/sus-app")
servr::httd('.', port = '80', host = '0.0.0.0', daemon = TRUE)
api_obj <- plumber::plumb('plumber.R')
api_obj$run(port = 8080, host = '0.0.0.0')
setwd("~/Documents/projects/nag/sus-app/R")
api_obj <- plumber::plumb('plumber.R')
api_obj$run(port = 8080, host = '0.0.0.0')
servr::httd('.', port = '80', host = '0.0.0.0', daemon = TRUE)
servr::httd('.', port = '8080', host = '0.0.0.0', daemon = TRUE)
servr::daemon_stop(0)
servr::daemon_stop(1)
servr::daemon_stop(2)
servr::daemon_stop(3)
servr::httd('.', port = '80', host = '0.0.0.0', daemon = TRUE)
setwd("~/Documents/projects/nag/sus-app")
servr::httd('.', port = '80', host = '0.0.0.0', daemon = TRUE)
servr::httd('.', port = '80', host = '0.0.0.0', daemon = TRUE)
servr::daemon_stop(1)
servr::httd('.', port = '80', host = '0.0.0.0', daemon = TRUE)
servr::daemon_stop(2)
servr::daemon_stop(3)
servr::httd('.', port = '80', host = '0.0.0.0', daemon = TRUE)
setwd("~/Documents/projects/nag/sus-app")
servr::httd('.', port = '80', host = '0.0.0.0', daemon = TRUE)
api_obj <- plumber::plumb('R/plumber.R')
api_obj$run(port = 8080, host = '0.0.0.0')
api_obj <- plumber::plumb('R/plumber.R')
getwd(0)
getwd()
api_obj <- plumber::plumb('R/plumber.R')
library(plumber)
library(servr)
api_obj <- plumber::plumb('R/plumber.R')
api_obj <- plumber::plumb('R/plumber.R')
api_obj <- plumber::plumb('R/plumber.R')
api_obj$run(port = 8080, host = '0.0.0.0')
