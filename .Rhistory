print('hello python')
print('hello python')
print('hello python')
print('hello python')
x = 10
x = [10, 20, 30]
print(x)
[i + 10 for i in x]
x = [10, 20, 30]
[i + 10 for i in x]
[i * 10 for i in x]
knitr::opts_chunk$set(echo = TRUE)
summary(cars)
print('hello')
print('test!!!')
reticulate::repl_python()
#---improved munge script for covid data
suppressWarnings({
suppressMessages({
library(data.table)
library(RSQLite)
library(DBI)
library(dplyr)
library(dbplyr)
library(mixdist)
library(extraDistr)
library(jsonlite)
library(geojsonio)
library(sp)
})
})
#setwd('~/working/cov_api/')
#functions used
rt.func.v2<-function(dat,mean.Weibull=4.8,sd.Weibull=2.3){
r.vals<-numeric(length = (length(dat) - 2))
#get the Weibull parameters from mixdist's weibullpar function
mGT.params<-weibullpar(mean.Weibull, sd.Weibull, loc = 0)
alpha<-mGT.params[2] # called shape in weibullpar, alpha in a discrete Weilbull
beta<-mGT.params[1] # called scale in weibullpar, beta in a discrete Weibull
#the extraDistr package uses an altrnative parameterization of the Weibull (q, beta) from
#Nakagawa and Osaki (1975) where q = exp(-alpha^-beta), so...
q<-exp(-as.numeric(alpha)^(-as.numeric(beta)))
#Discretize Weibull via the extraDistr package's ddweibull function
w<- ddweibull(0:1000, as.numeric(q), as.numeric(beta), log = FALSE)
growth<-diff(dat)
growth<-pmax(growth, 0) # eliminate any erroneous downward shifts in the cumulative counts
#Estimate R(t) from equation (33) of Nishiura and Chowell (2009)
for(k in 2:length(growth)){
r.vals[k-1]<-growth[k]/(sum(growth[1:k]*rev(w[1:k])))
}
#Output the results
return(c(NA, NA, r.vals))
}
covid_db <- dbConnect(RSQLite::SQLite(), '/Users/iankloo/working/cov_api/data/covid_db.sqlite')
#---check if need to update
suppressWarnings({
suppressMessages({
x <- tbl(covid_db, 'counties') %>%
filter(date == max(date, na.rm = TRUE)) %>%
select(date) %>%
collect()
})
})
db_date <- as.Date(x[1][[1]][1])
main <- fread('https://usafactsstatic.blob.core.windows.net/public/data/covid-19/covid_confirmed_usafacts.csv', colClasses = 'character', showProgress = FALSE)
main <- main[countyFIPS != '0']
keep_cols <- grep('V',colnames(main), invert = TRUE)
main <- main[, keep_cols, with=FALSE]
facts_date <- as.Date(colnames(main)[length(colnames(main))], format = '%m/%d/%y')
sub <- list(N = 21, J = 1, y = c(70.0, 75.0, 42.5, 70.0, 80.0, 65.0, 75.0, 80.0, 80.0, 67.5, 77.5, 75.0, 70.0, 57.5, 60.0, 62.5, 62.5, 47.5, 62.5, 82.5, 70.0), g = rep(1, 21))
new.fit <- stan(file = 'R/stanmod.stan', data = sub,refresh=0)
setwd("~/Documents/projects/nag/sus-app")
new.fit <- stan(file = 'R/stanmod.stan', data = sub,refresh=0)
library(plumber)
library(data.table)
library(rstan)
library(resample)
library(LaplacesDemon)
new.fit <- stan(file = 'R/stanmod.stan', data = sub,refresh=0)
bayes.est<-rstan::extract(new.fit,pars="mu[1]")$`mu[1]`
sig.est<-rstan::extract(new.fit,pars="sigma")$sigma
alpha=(0-bayes.est)/sig.est
beta=(100-bayes.est)/sig.est
ex.val<-bayes.est +
sig.est*(dnorm(alpha)-dnorm(beta))/
(pnorm(beta)-pnorm(alpha))
bayes.ci<-quantile(ex.val,probs=c(.025,.975))
ci <- matrix(c(bayes.ci[1], bayes.ci[2]), nrow = 1)
bayes <- list(sus_scores = sus_scores, ci = ci[1,], replicates = ex.val, mean = mean(ex.val), type = 'bayes')
N.bootstrap <- 2000
ci.hw.increase <- 0
b <- bootstrap(sus_scores, mean(sus_scores), R = N.bootstrap)
ci <- CI.bca(b, probs = c(0.025-ci.hw.increase, 0.975+ci.hw.increase), expand = TRUE)
ci
boot <- list(sus_scores = sus_scores, ci = ci[1,], replicates = b$replicates, mean = mean(sus_scores), type = 'boot')
x=seq(0,100,by=0.05)
dens <- dst(x, mu=mean(sus_scores), sigma=sd(sus_scores)/sqrt(length(sus_scores)), nu=length(sus_scores), log=FALSE)
sus_scores = y
y = c(70.0, 75.0, 42.5, 70.0, 80.0, 65.0, 75.0, 80.0, 80.0, 67.5, 77.5, 75.0, 70.0, 57.5, 60.0, 62.5, 62.5, 47.5, 62.5, 82.5, 70.0)
sus_scores = y
bayes.est<-rstan::extract(new.fit,pars="mu[1]")$`mu[1]`
sig.est<-rstan::extract(new.fit,pars="sigma")$sigma
alpha=(0-bayes.est)/sig.est
beta=(100-bayes.est)/sig.est
ex.val<-bayes.est +
sig.est*(dnorm(alpha)-dnorm(beta))/
(pnorm(beta)-pnorm(alpha))
bayes.ci<-quantile(ex.val,probs=c(.025,.975))
ci <- matrix(c(bayes.ci[1], bayes.ci[2]), nrow = 1)
bayes <- list(sus_scores = sus_scores, ci = ci[1,], replicates = ex.val, mean = mean(ex.val), type = 'bayes')
N.bootstrap <- 2000
ci.hw.increase <- 0
b <- bootstrap(sus_scores, mean(sus_scores), R = N.bootstrap)
ci <- CI.bca(b, probs = c(0.025-ci.hw.increase, 0.975+ci.hw.increase), expand = TRUE)
ci
boot <- list(sus_scores = sus_scores, ci = ci[1,], replicates = b$replicates, mean = mean(sus_scores), type = 'boot')
x=seq(0,100,by=0.05)
dens <- dst(x, mu=mean(sus_scores), sigma=sd(sus_scores)/sqrt(length(sus_scores)), nu=length(sus_scores), log=FALSE)
t_ci <- t.test(sus_scores)
x[1:10]
len(x)
length(x)
reticulate::repl_python()
